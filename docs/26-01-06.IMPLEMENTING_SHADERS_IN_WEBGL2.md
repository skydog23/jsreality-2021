## Implementing jReality-Style Programmable Shaders in WebGL2 (jsReality)

Date: 2026-06-01

### Goal

jReality’s scene graph centers on the idea that **shaders are programmable objects**: they don’t just hold parameters; they can **run code** (set GL state, bind textures/programs, choose draw paths, supply proxy geometry, etc.). This note summarizes where that “dispatch point” lives in JOGL and how we can port the same idea to jsReality’s WebGL2 renderer.

---

### What JOGL does (where shaders are invoked)

In JOGL, geometry rendering is explicitly orchestrated by `DefaultGeometryShader` and its sub-shaders. The key is that the renderer calls:

- `geometryShader.preRender(...)`
- then per primitive:
  - `pointShader.render(...)`, `pointShader.postRender(...)`
  - `lineShader.render(...)`, `lineShader.postRender(...)`
  - `polygonShader.render(...)`, `polygonShader.postRender(...)`
- then `geometryShader.postRender(...)`

The dispatch lives in `JOGLPeerGeometry.render()`:

```java
geometryShader.preRender(jr.renderingState, jpc);
if (geometryShader.isVertexDraw() && ps != null) {
  geometryShader.pointShader.render(jr.renderingState);
  geometryShader.pointShader.postRender(jr.renderingState);
}
if (geometryShader.isEdgeDraw() && ils != null) {
  geometryShader.lineShader.render(jr.renderingState);
  geometryShader.lineShader.postRender(jr.renderingState);
}
if (geometryShader.isFaceDraw() && isSurface) {
  geometryShader.polygonShader.render(jr.renderingState);
  geometryShader.polygonShader.postRender(jr.renderingState);
}
geometryShader.postRender(jr.renderingState);
```

#### Rendering hints are also “shader-like” in JOGL

`RenderingHintsShader` is applied per component via a stack (render + postRender delta semantics). This happens in `JOGLPeerComponent.preRender()/postRender()` (simplified):

```java
if (rhInfo != null && rhInfo.hasSomeActiveField) {
  rhInfo.render(jr.renderingState, jr.rhStack.lastElement());
  jr.rhStack.push(rhInfo);
}
// ... render geometry/children ...
if (rhInfo != null && rhInfo.hasSomeActiveField) {
  jr.rhStack.pop();
  rhInfo.postRender(jr.renderingState, jr.rhStack.lastElement());
}
```

This is important: in jReality, “hints” are part of the programmable pipeline, not just data.

---

### What jsReality has today (shader structure vs executable pipeline)

jsReality’s shader folder (`src/core/shader`) already provides:

- **Schema + default values** (e.g. `DefaultPointShader`, `DefaultPolygonShader`, `DefaultRenderingHintsShader`)
- **Resolved “instances”** from `EffectiveAppearance` (e.g. `PointShaderInstance`, `PolygonShaderInstance` via `DefaultGeometryShader.createFromEffectiveAppearance(...)`)
- **Named shader registry** (`ShaderRegistry`) for non-default shader selection (e.g. polygon shader `"implode"`)

However, the WebGL2 renderer currently treats these mostly as **parameter bags**, and the “programmable” behavior is implemented directly in the renderer.

#### One key programmable feature already exists: proxy geometry

`Abstract2DRenderer.visitIndexedFaceSet()` already implements jReality’s “shader can replace geometry” concept:

```js
const geometryShader = DefaultGeometryShader.createFromEffectiveAppearance(this.#effectiveAppearance);
const polygonShader = geometryShader.getPolygonShader();
if (polygonShader.providesProxyGeometry()) {
  const proxyGeometry = polygonShader.getProxyGeometry(faceSet);
  if (proxyGeometry) geometryToRender = proxyGeometry;
}
```

This is a good foundation: it shows we can hang executable behavior off shader objects while keeping `EffectiveAppearance`-driven resolution.

---

### Suggested WebGL2 porting approach (keep semantics, modernize implementation)

#### 1) Add an executable “shader adapter” layer for WebGL2

Keep the existing shader instances (great for inspector + inheritance), but add a WebGL2-facing interface that mirrors JOGL’s orchestration points:

- `geometryShader.preRender(ctx)` / `geometryShader.postRender(ctx)`
- `pointShader.render(ctx, geometry)` / `pointShader.postRender(ctx)`
- `lineShader.render(ctx, geometry)` / `lineShader.postRender(ctx)`
- `polygonShader.render(ctx, geometry)` / `polygonShader.postRender(ctx)`

Where `ctx` is a lightweight “render context” object containing:

- `gl` + cached programs/buffers
- current matrices / object2world / world2cam (for lighting, culling, normal transforms)
- current `EffectiveAppearance` (or already-resolved shader instances)
- per-frame stats/debug counters
- a `hintsStack` for RenderingHintsShader (see below)

This keeps the core idea: **shaders are objects with behavior**.

#### 2) Implement RenderingHintsShader as a real WebGL state layer (push/pop)

Mirror JOGL’s stack-based hint semantics:

- Depth test enable/disable, depth mask (zBuffer)
- Blend enable + mode (normal vs additive), transparency enable
- Culling enable/disable and front-face winding (plus flipNormals interaction)
- Polygon offset / depth fudge factor

Recommendation: implement a `WebGL2RenderingHints` adapter that can compute deltas relative to parent and restore on pop, even if internally we just set “absolute” state each time (WebGL state is global and sticky).

#### 3) Keep traversal semantics for correctness; postpone batching-by-program

JOGL’s side effects occur during traversal; that’s the easiest compatibility target.

We can still optimize within traversal:

- caching and reusing programs
- instancing for points/tubes/spheres (already exists)
- limited batching inside a shader (e.g., WebGL2Renderer’s existing face batching)

But we should avoid a large “sort by material/program” batching pass until the programmable shader semantics are nailed down (because that can change ordering-dependent behavior).

---

### Questions (to decide scope and avoid designing into a corner)

- **Custom GLSL support**: Do we want user-provided GLSL source attached to `Appearance` (like JOGL’s `USE_GLSL` path), or should “programmable” initially mean “named shaders implemented in JS and compiled from built-in GLSL templates”?
- **Override power**: Should a shader be allowed to fully override drawing for a primitive type (e.g., a polygon shader draws a special multipass effect), or only allowed to set uniforms/state and let the renderer draw?
- **Ordering guarantees**: Should we preserve strict traversal order (JOGL-like), or is it acceptable to reorder draws for batching once things are stable?
- **Hints semantics**: Do we want exact JOGL-like “delta relative to parent” semantics for `RenderingHintsShader`, or is “resolve effective hints once and apply absolute state” sufficient?
- **Shader selection API**: Should point/line shaders also support named shader selection (like polygon already does via `ShaderRegistry`), or start with polygon only?

---

### Concrete next steps (minimal viable programmable pipeline)

- Add a small `WebGL2RenderContext` object type passed around during rendering.
- Add `preRender/postRender` hooks to the WebGL2 shader adapters:
  - start with `RenderingHintsShader` and `PolygonShader` (since polygon is already the richest and has proxy geometry).
- Wire the orchestration to mirror `JOGLPeerGeometry.render()`:
  - geometry preRender
  - point/line/polygon render+postRender
  - geometry postRender
- Keep current WebGL2Renderer behavior as the default implementations behind these hooks, so the change is initially refactoring + extension points, not a rewrite.


